{
 "metadata": {
  "name": "",
  "signature": "sha256:4a92665e9d79b4b1f58ae45671cb80482e4fcef92ff34e015a672ad48d7de2df"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "import re\n",
      "import os\n",
      "import glob\n",
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parse Recode (.DCF file) into dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code moved to external file so that FME can also read it\n",
      "from DCF_Parser_Main import parseDCF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#r'C:\\Users\\zool1301\\Documents\\DHS\\RecodeManuals\\Recode6.dcf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parse all DCF files in a directory and write spec to CSV (for db import etc)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#inDir = r'C:\\Users\\zool1301\\Documents\\DHS\\Acquisition\\20150626_FullSiteScrape\\downloads\\358'\n",
      "#outDir = r'C:\\Users\\zool1301\\Documents\\DHS\\Acquisition\\20150626_FullSiteScrape\\ParsedSpecs'\n",
      "inDir = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Acquisition\\AdditionalDownloads\\259'\n",
      "outDir = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Acquisition\\AdditionalDownloads\\259\\OutSpecs'\n",
      "#inDir = r'C:\\Users\\zool1301\\Documents\\DHS\\RecodeManuals'\n",
      "#outDir = r'C:\\Users\\zool1301\\Documents\\DHS\\RecodeManuals\\Parsed'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Specify what columns the CSV should have - these must be things that the DCF parser generates\n",
      "reqfieldnames = ['ItemType', 'FileCode','RecordName','RecordTypeValue','RecordLabel','Name','Label',\n",
      "                 'Start','Len','Occurrences','ZeroFill', 'DecimalChar', 'Decimal', 'FMETYPE']\n",
      "valfieldnames = ['FileCode','Name','Value','ValueDesc', 'ValueType']\n",
      "relfieldnames = ['FileCode', 'RelName', 'PrimaryTable', 'PrimaryLink', 'SecondaryTable', 'SecondaryLink']\n",
      "#inDir = r'C:\\Users\\zool1301\\Documents\\DHS\\Acquisition\\20150626_FullSiteScrape\\downloads\\358'\n",
      "#outDir = r'C:\\Users\\zool1301\\Documents\\DHS\\Acquisition\\20150626_FullSiteScrape\\ParsedSpecs'\n",
      "#inDir = r'C:\\Users\\zool1301\\Documents\\DHS\\RecodeManuals'\n",
      "#outDir = r'C:\\Users\\zool1301\\Documents\\DHS\\RecodeManuals\\Parsed'\n",
      "\n",
      "inputDCFs = glob.glob(os.path.join(inDir,'*','*.dcf'))\n",
      "for inputDCF in inputDCFs:\n",
      "    print inputDCF\n",
      "    parsedDCFItems, parsedDCFRelations = parseDCF(inputDCF)\n",
      "    inBase = os.path.extsep.join(os.path.basename(inputDCF).split(os.path.extsep)[:-1])\n",
      "    #inBase = os.path.basename(inputDCF).split(os.path.extsep)[0]\n",
      "    outBase = inBase + '.FlatRecordSpec.csv'\n",
      "    outValsBase = inBase + '.FlatValuesSpec.csv'\n",
      "    outRelsBase = inBase + '.RelationshipsSpec.csv'\n",
      "    outFileName = os.path.join(outDir,outBase)\n",
      "    outValsFileName = os.path.join(outDir, outValsBase)\n",
      "    outRelsFileName = os.path.join(outDir, outRelsBase)\n",
      "    #item = parsedDCF[0]\n",
      "    #write.writerow([item['FileCode'], item['])\n",
      "    with open(outFileName, 'wb') as fout, open(outValsFileName, 'wb') as fValsOut, \\\n",
      "            open(outRelsFileName, 'wb') as fRelsOut:\n",
      "        wri = csv.writer(fout)\n",
      "        wri.writerow(reqfieldnames)\n",
      "        wriVals = csv.writer(fValsOut)\n",
      "        wriVals.writerow(valfieldnames)\n",
      "        wriRels = csv.writer(fRelsOut)\n",
      "        wriRels.writerow(relfieldnames)\n",
      "        for item in parsedDCFItems:\n",
      "            item['FMETYPE'] = \"fme_char({0!s})\".format(item['Len'])\n",
      "            # write the row using the fieldnames given in reqfieldnames\n",
      "            # not all items have \"occurrences\", \"range_low_value\", etc so write blank value if not\n",
      "            wri.writerow([item[k] if item.has_key(k) else '' for k in reqfieldnames])\n",
      "            # write the value sets to a separate file\n",
      "            if 'Values' in item and len(item['Values'])>0:\n",
      "                vals = item['Values']\n",
      "                for val in vals:\n",
      "                    wriVals.writerow([item['FileCode'],item['Name'], val[0], val[1], val[2]])\n",
      "        for item in parsedDCFRelations:\n",
      "            wriRels.writerow([item[k] if item.has_key(k) else '' for k in relfieldnames])\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\\\\129.67.26.176\\map_data\\DHS_Automation\\Acquisition\\AdditionalDownloads\\259\\szir51\\259.szir51.dcf\n",
        "Parsed 28562 lines into 1769 items"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\\\\129.67.26.176\\map_data\\DHS_Automation\\Acquisition\\AdditionalDownloads\\259\\szar51\\szar51.dcf"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Parsed 78 lines into 7 items\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rename files to include survey id number\n",
      "allFiles = glob.glob(os.path.join(inDir,'*','*'))\n",
      "for fn in allFiles:\n",
      "    if str.lower(fn).find('.zip') != -1:\n",
      "        continue\n",
      "    basename = os.path.basename(fn)\n",
      "    dirname = os.path.dirname(fn)\n",
      "    idname = os.path.basename(dirname)\n",
      "    newname = idname+'.'+basename\n",
      "    newpath = os.path.join(dirname,newname)\n",
      "    #print fn\n",
      "    #print newpath\n",
      "    os.rename(fn,newpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Naive sql generation of output (not used: use FME if loading to DB; this workbook creates CSVs)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "levelsInserts = []\n",
      "recordsInserts = []\n",
      "itemsInserts = []\n",
      "valuesInserts = []\n",
      "\n",
      "# i think a straightforward bit of sql formatting will do here, nobody malicious will get chance to run...\n",
      "\n",
      "# levels is straightforward, just name and label\n",
      "for name, label in allLevels.iteritems():\n",
      "    insertLevelsSQL = 'INSERT INTO dhs_levels '\\\n",
      "    '(record_name, record_label)' \\\n",
      "    ' VALUES '\\\n",
      "    '(\"{0!s}\", \"{1!s}\");'.format(name, label)\n",
      "    levelsInserts.append(insertLevelsSQL)\n",
      "    \n",
      "# records may be country specific, impute this from the presence of a word followed by \"specific\"\n",
      "# in the label. E.g. \"Country specific\", \"Survey specific\"\n",
      "for name, label in allRecords.iteritems():\n",
      "    m = re.match('^\\w+ specific', label)\n",
      "    if m:\n",
      "        specificText = m.group(0)\n",
      "    else:\n",
      "        specificText = \"No\"\n",
      "        \n",
      "    insertRecordsSQL = 'INSERT INTO dhs_records '\\\n",
      "    '(record_name, record_label, c_or_s_specific)' \\\n",
      "    ' VALUES '\\\n",
      "    '(\"{0!s}\", \"{1!s}\", \"{2!s}\");'.format(name, label, specificText)\n",
      "    recordsInserts.append(insertRecordsSQL)\n",
      "    \n",
      "# items is the main thingy\n",
      "for item in allItems:\n",
      "    insertItemsSQL = 'INSERT INTO dhs_recodes '\\\n",
      "    '(level_id, record_id, recode_id, recode_description, start, len, data_type, item_type, range_low_value, range_high_value)'\\\n",
      "    ' VALUES '\\\n",
      "    '(\"{0!s}\", \"{1!s}\", \"{2!s}\", \"{3!s}\", {4!s}, {5!s}, {6!s}, {7!s}, {8!s}, {9!s});'.format(\n",
      "        item['LevelName'], item['RecordName'], item['Name'], item['Label'], item['Start'], item['Len'], \n",
      "        '\"A\"', '\"B\"', # TODO change these\n",
      "        item['Range_Low_Value'] if item.has_key('Range_Low_Value') else '',\n",
      "        item['Range_High_Value'] if item.has_key('Range_High_Value') else '',\n",
      "    )\n",
      "    itemsInserts.append(insertItemsSQL)\n",
      "    if item.has_key('Values') and len(item['Values'])>0:\n",
      "        for valtuple in item['Values']:\n",
      "            insertValueSQL = 'INSERT INTO dhs_recode_values '\\\n",
      "            '(recode_id, value_code, value_description)' \\\n",
      "            ' VALUES '\\\n",
      "            '(\"{0!s}\", \"{1!s}\", \"{2!s}\");'.format(\n",
      "                item['Name'], valtuple[0], valtuple[1])\n",
      "            valuesInserts.append(insertValueSQL)\n",
      "#print insertSQL\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}