{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/pg_conn.txt') as conn_details:\n",
    "    conn_str_psyco = conn_details.readline()\n",
    "    conn_str_sqlalchemy = conn_details.readline()\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as sa\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(conn_str_sqlalchemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_SCHEMA = 'dhs_survey_specs'\n",
    "DATA_SCHEMA = 'dhs_data_tables'\n",
    "\n",
    "#TABLESPEC_TABLENAME = 'table_specs_blank' #'dhs_table_specs_flat'\n",
    "TABLESPEC_TABLENAME = 'dhs_table_specs_flat'\n",
    "#VALUESPEC_TABLENAME = 'value_specs_blank' #'dhs_value_descs'\n",
    "VALUESPEC_TABLENAME = 'dhs_value_descs'\n",
    "#SURVEYLIST_TABLENAME = 'dhs_survey_listing_backup'\n",
    "SURVEYLIST_TABLENAME = 'dhs_survey_listing'\n",
    "\n",
    "TABLE_SPEC_TABLE = \".\".join((SPEC_SCHEMA, TABLESPEC_TABLENAME))\n",
    "VALUE_SPEC_TABLE = \".\".join((SPEC_SCHEMA, VALUESPEC_TABLENAME))\n",
    "SURVEYLIST_TABLE = \".\".join((SPEC_SCHEMA, SURVEYLIST_TABLENAME))\n",
    "\n",
    "STAGING_FOLDER = \"/mnt/d/InformalCities/DHS_Updates/staging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"REC01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " surveyid character varying(3) COLLATE pg_catalog.\"default\",\n",
    "    caseid character varying(18) COLLATE pg_catalog.\"default\",\n",
    "    v000 character varying(3) COLLATE pg_catalog.\"default\",\n",
    "    v001 character varying(8) COLLATE pg_catalog.\"default\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Executes the given construct and returns a\n",
       ":class:`_engine.ResultProxy`.\n",
       "\n",
       "The arguments are the same as those used by\n",
       ":meth:`_engine.Connection.execute`.\n",
       "\n",
       "Here, a :class:`_engine.Connection` is acquired using the\n",
       ":meth:`_engine.Engine.contextual_connect` method,\n",
       "and the statement executed\n",
       "with that connection. The returned :class:`_engine.ResultProxy`\n",
       "is flagged\n",
       "such that when the :class:`_engine.ResultProxy` is exhausted and its\n",
       "underlying cursor is closed, the :class:`_engine.Connection`\n",
       "created here\n",
       "will also be closed, which allows its associated DBAPI connection\n",
       "resource to be returned to the connection pool.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/geodev_38/lib/python3.8/site-packages/sqlalchemy/engine/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engine.execute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = engine.execute(\"\"\"SELECT\n",
    "    tablename,\n",
    "    indexname,\n",
    "    indexdef\n",
    "FROM\n",
    "    pg_indexes\n",
    "WHERE\n",
    "    schemaname = 'dhs_data_tables'\n",
    "ORDER BY\n",
    "    tablename,\n",
    "    indexname;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a \"raw\" DBAPI connection from the connection pool.\n",
       "\n",
       "The returned object is a proxied version of the DBAPI\n",
       "connection object used by the underlying driver in use.\n",
       "The object will have all the same behavior as the real DBAPI\n",
       "connection, except that its ``close()`` method will result in the\n",
       "connection being returned to the pool, rather than being closed\n",
       "for real.\n",
       "\n",
       "This method provides direct DBAPI connection access for\n",
       "special situations when the API provided by\n",
       ":class:`_engine.Connection`\n",
       "is not needed.   When a :class:`_engine.Connection` object is already\n",
       "present, the DBAPI connection is available using\n",
       "the :attr:`_engine.Connection.connection` accessor.\n",
       "\n",
       ".. seealso::\n",
       "\n",
       "    :ref:`dbapi_connections`\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/geodev_38/lib/python3.8/site-packages/sqlalchemy/engine/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engine.raw_connection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_helper = TableDataHelper(conn_str=conn_str_sqlalchemy, table_spec_table=TABLESPEC_TABLENAME,\n",
    "                             value_spec_table=VALUESPEC_TABLENAME, spec_schema=SPEC_SCHEMA,\n",
    "                           data_schema=DATA_SCHEMA, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_helper._does_data_table_exist(\"RECHEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_helper._is_dry_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_helper._is_dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped existing index surveyid_rechem\n",
      "Skipped existing index hhid_rechem\n",
      "Skipped existing index idxhe_rechem\n",
      "Skipped existing covering index allidx_rechem\n",
      "Skipped existing seoncdary covering index twoidx_rechem\n",
      "Would create table with \n",
      "\n",
      "            CREATE TABLE dhs_data_tables.\"RECHEM\"(surveyid character varying(3) COLLATE pg_catalog.\"default\",\n",
      "hhid character varying(12) COLLATE pg_catalog.\"default\",\n",
      "idxhe character varying(2) COLLATE pg_catalog.\"default\",\n",
      "sh63 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh64 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh65 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh66 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh67 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh68 character varying(2) COLLATE pg_catalog.\"default\",\n",
      "sh69 character varying(3) COLLATE pg_catalog.\"default\",\n",
      "sh70 character varying(3) COLLATE pg_catalog.\"default\",\n",
      "sh71 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh72 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh73 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh74 character varying(1) COLLATE pg_catalog.\"default\",\n",
      "sh75 character varying(1) COLLATE pg_catalog.\"default\")\n",
      "            TABLESPACE pg_default;\n",
      "            ALTER TABLE dhs_data_tables.\"RECHEM\" OWNER to admin;\n",
      " then create indices with \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = db_helper.create_data_table(\"RECHEM\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = engine.execute(f'SELECT * FROM dhs_data_tables.\"RECH1\" LIMIT 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>maxlen</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aidsex</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caseid</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  maxlen  start\n",
       "0  aidsex       1    157\n",
       "1  caseid      18      1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(f\"\"\"\n",
    "            SELECT LOWER(name) AS name, MAX(len) AS maxlen, MAX(start) as start\n",
    "            FROM {TABLE_SPEC_TABLE}\n",
    "            WHERE recordname = '{table_name}' AND lower(name) LIKE '%id%'\n",
    "            GROUP BY name\"\"\", con=engine)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "whats_needed.loc[-1] = ('surveyid', 'Item', '3', 0)\n",
    "whats_needed.index = whats_needed.index + 1  # shifting index\n",
    "whats_needed.sort_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "whats_needed.loc[len(whats_needed)] = ('data', 'Item', '', 999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>itemtype</th>\n",
       "      <th>length</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surveyid</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caseid</td>\n",
       "      <td>IdItem</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v001</td>\n",
       "      <td>Item</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v002</td>\n",
       "      <td>Item</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v003</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v004</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v005</td>\n",
       "      <td>Item</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v008a</td>\n",
       "      <td>Item</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>v006</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>v007</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>v008</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>v009</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>v010</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>v011</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>v012</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>v013</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>v014</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>v015</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>v016</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>v017</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>v018</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>v019</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>v019a</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>v020</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>v021</td>\n",
       "      <td>Item</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>v022</td>\n",
       "      <td>Item</td>\n",
       "      <td>5</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>v024</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>v025</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>v026</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>v027</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>v028</td>\n",
       "      <td>Item</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>v033</td>\n",
       "      <td>Item</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>v034a</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mrec01_group</td>\n",
       "      <td>Item</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>v029</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mv034</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>v034b</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mv034a</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>v030</td>\n",
       "      <td>Item</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mv034b</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>v031</td>\n",
       "      <td>Item</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>v032</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>v034</td>\n",
       "      <td>Item</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>v043</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>v000</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>v040</td>\n",
       "      <td>Item</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>v042</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>v044</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>v045a</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>v045b</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>v023</td>\n",
       "      <td>Item</td>\n",
       "      <td>5</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>v045c</td>\n",
       "      <td>Item</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>v046</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>v035</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>hivwt</td>\n",
       "      <td>Item</td>\n",
       "      <td>8</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>mv035</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>aidsex</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>aisexact</td>\n",
       "      <td>Item</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>data</td>\n",
       "      <td>Item</td>\n",
       "      <td></td>\n",
       "      <td>999999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name itemtype length      start\n",
       "0       surveyid     Item      3          0\n",
       "1         caseid   IdItem     18          1\n",
       "2           v001     Item      8         34\n",
       "3           v002     Item      6         42\n",
       "4           v003     Item      3         46\n",
       "5           v004     Item      4         49\n",
       "6           v005     Item      8         53\n",
       "7          v008a     Item      5         59\n",
       "8           v006     Item      2         61\n",
       "9           v007     Item      4         63\n",
       "10          v008     Item      4         67\n",
       "11          v009     Item      2         71\n",
       "12          v010     Item      4         73\n",
       "13          v011     Item      4         77\n",
       "14          v012     Item      2         81\n",
       "15          v013     Item      2         83\n",
       "16          v014     Item      1         84\n",
       "17          v015     Item      1         85\n",
       "18          v016     Item      2         86\n",
       "19          v017     Item      4         88\n",
       "20          v018     Item      2         92\n",
       "21          v019     Item      2         94\n",
       "22         v019a     Item      1         96\n",
       "23          v020     Item      1         97\n",
       "24          v021     Item      6         98\n",
       "25          v022     Item      5        102\n",
       "26          v024     Item      2        108\n",
       "27          v025     Item      1        110\n",
       "28          v026     Item      1        111\n",
       "29          v027     Item      1        112\n",
       "30          v028     Item      6        113\n",
       "31          v033     Item      8        115\n",
       "32         v034a     Item      1        115\n",
       "33  mrec01_group     Item      5        116\n",
       "34          v029     Item      3        116\n",
       "35         mv034     Item      2        116\n",
       "36         v034b     Item      2        116\n",
       "37        mv034a     Item      1        118\n",
       "38          v030     Item      6        118\n",
       "39        mv034b     Item      2        119\n",
       "40          v031     Item      6        121\n",
       "41          v032     Item      3        127\n",
       "42          v034     Item      2        130\n",
       "43          v043     Item      1        130\n",
       "44          v000     Item      3        131\n",
       "45          v040     Item      4        132\n",
       "46          v042     Item      1        136\n",
       "47          v044     Item      1        137\n",
       "48         v045a     Item      3        138\n",
       "49         v045b     Item      3        141\n",
       "50          v023     Item      5        143\n",
       "51         v045c     Item      3        144\n",
       "52          v046     Item      1        147\n",
       "53          v035     Item      1        153\n",
       "54         hivwt     Item      8        155\n",
       "55         mv035     Item      1        156\n",
       "56        aidsex     Item      1        157\n",
       "57      aisexact     Item      1        158\n",
       "58          data     Item         999999999"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whats_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "class TableDataHelper:\n",
    "    _MAX_COLUMN_THRESHOLD = 1000\n",
    "    def __init__(self, conn_str, \n",
    "        table_spec_table, value_spec_table, spec_schema,\n",
    "        data_schema, dry_run=True):\n",
    "        self._engine = create_engine(conn_str)\n",
    "        self._TABLE_SPEC_TABLENAME = table_spec_table\n",
    "        self._VALUE_SPEC_TABLENAME = value_spec_table\n",
    "        self._SPEC_SCHEMA = spec_schema\n",
    "        self._TABLE_SPEC_TABLE = \".\".join([spec_schema, table_spec_table])\n",
    "        self._VALUE_SPEC_TABLE = \".\".join([spec_schema, value_spec_table])\n",
    "        self._DATA_SCHEMA = data_schema\n",
    "        self._is_dry_run = dry_run\n",
    "        \n",
    "        self._populate_JSON_table_list()\n",
    "        \n",
    "        self._known_tables = set()\n",
    "        self._checked_column_tables = set()\n",
    "\n",
    "    \n",
    "    def _populate_JSON_table_list(self):\n",
    "        json_tables = pd.read_sql(f\"\"\"\n",
    "            SELECT DISTINCT table_name \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_schema = '{self._DATA_SCHEMA}' AND data_type = 'jsonb'\"\"\",\n",
    "                con=self._engine)\n",
    "        self._json_tables = set(json_tables['table_name'])\n",
    "\n",
    "    def _does_data_table_exist(self, table_name):\n",
    "        if table_name in self._known_tables:\n",
    "            return True\n",
    "        exists = pd.read_sql(f\"\"\"\n",
    "            SELECT EXISTS (\n",
    "                SELECT FROM information_schema.tables \n",
    "                WHERE  table_schema = '{self._DATA_SCHEMA}'\n",
    "                AND    table_name   = '{table_name}'\n",
    "            );\"\"\", con=self._engine)['exists'][0]\n",
    "        if exists:\n",
    "            self._known_tables.add(table_name)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def prepare_db_for_file(self, table_name):\n",
    "        if not self._does_data_table_exist(table_name):\n",
    "            self.create_data_table(table_name)\n",
    "        else:\n",
    "            self.check_cols_against_metadata(table_name)\n",
    "\n",
    "\n",
    "    def create_data_table(self, table_name):\n",
    "        \"\"\"Creates a data table with all the columns that are currently specified in the metadata.\n",
    "        \n",
    "        As throughout this software, all columns are created with VARCHAR(n) type where n = the \n",
    "        maximum width currently specified for that table/column in any survey\n",
    "        \n",
    "        The exception if there are more than TableDataHelper._MAX_COLUMN_THRESHOLD columns \n",
    "        specified in the metadata, in which case only columns with \"id\" in the name will be \n",
    "        first-class columns, and a jsonb column named data will be added for storing the remainder.\"\"\"\n",
    "        column_clauses, is_json = self._get_column_clauses(table_name)\n",
    "        create_stmt = f\"\"\"\n",
    "            CREATE TABLE {self._DATA_SCHEMA}.\"{table_name}\"({column_clauses})\n",
    "            TABLESPACE pg_default;\n",
    "            ALTER TABLE {self._DATA_SCHEMA}.\"{table_name}\" OWNER to admin;\"\"\"\n",
    "        if self._is_dry_run:\n",
    "            return (\"Would create table with \\n\" + create_stmt + \"\\n\" \n",
    "            + \" then create indices with \" + self._create_or_replace_indices(table_name, is_json))\n",
    "        else:\n",
    "            r = self._engine.execute(create_stmt)\n",
    "            index_sql = self._create_or_replace_indices(table_name, is_json)\n",
    "            if len(index_sql) > 0:\n",
    "                print(\"Executing the following to drop / recreate indices: \\n\" + index_sql)\n",
    "                self._engine.execute(index_sql)\n",
    "        \n",
    "\n",
    "    def _get_column_clauses(self, table_name):\n",
    "        \"\"\"Gets the columns that a new data table should have, according to the metadata tables.\n",
    "        \n",
    "        Returns them as a string for use in a statement of the form \n",
    "        CREATE TABLE tablename (result) \"\"\"\n",
    "        \n",
    "        # list all columns that are specified for this datatable in the survey metadata (unioned \n",
    "        # set across all surveys: not all surveys will have all columns)\n",
    "        whats_needed = pd.read_sql(f\"\"\"\n",
    "            SELECT lower(name) AS name, itemtype, MAX(len) AS length, MAX(start) AS start\n",
    "            FROM {self._TABLE_SPEC_TABLE}\n",
    "            WHERE recordname='{table_name}'\n",
    "            GROUP BY name, itemtype\n",
    "            ORDER BY start;\n",
    "        \"\"\", con=self._engine)\n",
    "        \n",
    "        # In the case of some country-specific tables, where the columns are different in almost \n",
    "        # every survey, the number of columns becomes very large and horribly inefficient to store \n",
    "        # (it is sparse). In these cases we store those tables with a single JSONB column for the data \n",
    "        # plus the ID/joining columns as first-class columns\n",
    "        is_json = False\n",
    "        if len(whats_needed) > TableDataHelper._MAX_COLUMN_THRESHOLD:\n",
    "            whats_needed = whats_needed[whats_needed['name'].str.contains('id')]\n",
    "            whats_needed.loc[len(whats_needed)] = ('data', 'JSON', '', 99999999)\n",
    "            is_json=True\n",
    "\n",
    "        # of course the metadata tables don't specify surveyid so we add that manually\n",
    "        whats_needed.loc[-1] = ('surveyid', 'Item', '3', 0)\n",
    "        whats_needed.index = whats_needed.index + 1\n",
    "        whats_needed.sort_index(inplace=True)\n",
    "        \n",
    "        def _clause_from_row(r):\n",
    "            if r[\"itemtype\"] == \"JSON\":\n",
    "                type_clause = \"jsonb\"\n",
    "            else:\n",
    "                type_clause = f'character varying({r[\"length\"]})'\n",
    "            clause = f'{r[\"name\"]} {type_clause} COLLATE pg_catalog.\"default\"'\n",
    "            return clause \n",
    "\n",
    "        # convert each row in the df to a clause for use in the CREATE TABLE statement\n",
    "        clauses = list(whats_needed.apply(_clause_from_row, axis=1))\n",
    "        return (\",\\n\".join(clauses), is_json)\n",
    "\n",
    "\n",
    "    def _create_or_replace_indices(self, table_name, is_json=False, replace_existing=False):\n",
    "        # TODO create GIN index on any JSON columns?\n",
    "        idx_sql_template = 'CREATE INDEX {0} ON {1}.\"{2}\"({3});'\n",
    "        idx_name_template = '{0}_{1}'\n",
    "        clean_sql_template = 'DROP INDEX IF EXISTS {0}.{1};'\n",
    "\n",
    "        res = self._engine.execute(\"SELECT relname FROM pg_class WHERE relkind='i';\")\n",
    "        existing_indices = [i[0] for i in res.fetchall()]\n",
    "\n",
    "        tbl_cols = self._engine.execute(f'SELECT * FROM dhs_data_tables.\"{table_name}\" LIMIT 0').keys()\n",
    "        idx_fields = [c for c in tbl_cols if c.find('id') != -1]\n",
    "\n",
    "        drop_idx_stmts = []\n",
    "        idx_stmts = []\n",
    "\n",
    "        for c in idx_fields:\n",
    "            idx_name = idx_name_template.format(c, str.lower(table_name))\n",
    "            idx_sql = idx_sql_template.format(idx_name, self._DATA_SCHEMA, table_name, c)\n",
    "            if idx_name in existing_indices:\n",
    "                if replace_existing:\n",
    "                    drop_idx_stmt = clean_sql_template.format(self._DATA_SCHAME, idx_name)\n",
    "                    drop_idx_stmts.append(drop_idx_stmt)\n",
    "                    idx_stmts.append(idx_sql)\n",
    "                    print(\"Replacing index \" + idx_name)\n",
    "                else:\n",
    "                    print(\"Skipped existing index \" + idx_name)\n",
    "            else:\n",
    "                idx_stmts.append(idx_sql)\n",
    "                print(\"Adding index \"+idx_name)\n",
    "        \n",
    "        # also create a single covering index on all joining columns\n",
    "        if len(idx_fields) > 1:\n",
    "            idx_name = idx_name_template.format(\"allidx\", str.lower(table_name))\n",
    "            idx_sql = idx_sql_template.format(idx_name, self._DATA_SCHEMA, table_name, \",\".join(idx_fields))\n",
    "            if idx_name in existing_indices:\n",
    "                if replace_existing:\n",
    "                    drop_idx_stmt = clean_sql_template.format(self._DATA_SCHEMA, idx_name)\n",
    "                    drop_idx_stmts.append(drop_idx_stmt)\n",
    "                    idx_stmts.append(idx_sql)\n",
    "                    print(\"Replacing covering index \" + idx_name)\n",
    "                else:\n",
    "                    print(\"Skipped existing covering index \" + idx_name)\n",
    "            else:\n",
    "                idx_stmts.append(idx_sql)\n",
    "                print(\"Adding covering index \"+idx_name)\n",
    "        \n",
    "        # also create a covering index on the first two joining columns if there are three \n",
    "        # (or all except the last one, if there's more)\n",
    "        # e.g. surveyid and caseid but not bidx (the cols are in the appropriate order in the CSVs)\n",
    "        if len(idx_fields) > 2:\n",
    "            idx_name = idx_name_template.format(\"twoidx\", str.lower(table_name))\n",
    "            idx_sql = idx_sql_template.format(idx_name, self._DATA_SCHEMA,\n",
    "                                            table_name, \",\".join(idx_fields[:-1]))\n",
    "            if idx_name in existing_indices:\n",
    "                if replace_existing:\n",
    "                    drop_idx_stmt = clean_sql_template.format(self._DATA_SCHEMA, idx_name)\n",
    "                    drop_idx_stmts.append(drop_idx_stmt)\n",
    "                    idx_stmts.append(idx_sql)\n",
    "                    print (\"Replacing secondary covering index \" + idx_name)\n",
    "                else:\n",
    "                    print (\"Skipped existing seoncdary covering index \" + idx_name)\n",
    "            else:\n",
    "                idx_stmts.append(idx_sql)\n",
    "                print (\"Adding secondary covering index \" + idx_name)\n",
    "        \n",
    "        drop_indices_sql = \"\\n\".join(drop_idx_stmts)\n",
    "        create_indices_sql = \"\\n\".join(idx_stmts)\n",
    "\n",
    "        return drop_indices_sql + \"\\n\" + create_indices_sql\n",
    "  \n",
    "\n",
    "    def get_db_survey_table_rowcount(self, surveyid, tablename):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def check_and_update_column_width(self, schema_name, table_name, column_name, \n",
    "                                req_width, update_if_needed=False):\n",
    "        \"\"\"Check that a varchar(n) column in the database is at least req_width wide and widen it if not\"\"\"\n",
    "        df = pd.read_sql(f'''\n",
    "            SELECT character_maximum_length as maxlen \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = '{table_name}' and column_name = '{column_name}';''', con=self._engine)\n",
    "        current = df['maxlen'][0]\n",
    "        if current < req_width and update_if_needed:\n",
    "            print(f\"Column {schema_name}.{table_name}.{column_name} will be widened from\"+\n",
    "                \"{current} to {req_width}\")\n",
    "            sql = f'''ALTER TABLE {schema_name}.\"{table_name}\" \n",
    "                        ALTER COLUMN {column_name} TYPE character varying({req_width})'''\n",
    "            return self._engine.execute(sql)\n",
    "        else:\n",
    "            return current >= req_width\n",
    "\n",
    "\n",
    "    def check_destination_col_widths(self, df, schema_name, table_name):\n",
    "        \"\"\"Check that for all object columns in the provided dataframe, the equivalent column \n",
    "        in the database is at least wide enough to hold it, and widen it if not.\"\"\"\n",
    "        obj_cols = df.select_dtypes(include=['object']).columns\n",
    "        lengths = {col:(df[col].str.len().max()) for col in obj_cols}\n",
    "        for col, incoming_length in lengths.items():\n",
    "            self.check_and_update_column_width(schema_name, table_name, col, incoming_length, True)\n",
    "\n",
    "    \n",
    "    def check_missing_cols(self, table_name):\n",
    "        \"\"\"For a given data table, check the metadata tables to see what all the columns \n",
    "        needed are, and then check whether they all exist. Returns a dataframe of column names \n",
    "        that are missing from the table, if the table is not one with a JSONB column.\"\"\"\n",
    "        \n",
    "        data_cols_needed = pd.read_sql(f\"\"\"\n",
    "            SELECT recordname, LOWER(name) AS name, MAX(len) AS maxlen \n",
    "            FROM {self._SPEC_SCHEMA}.{self._TABLE_SPEC_TABLENAME}\n",
    "            WHERE recordname != '*'\n",
    "            GROUP BY recordname, name\n",
    "            ORDER BY recordname, name\"\"\", con=self._engine)\n",
    "        \n",
    "        data_cols_present = pd.read_sql(f\"\"\"\n",
    "            SELECT table_name, column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_schema = '{self._DATA_SCHEMA}' ORDER BY table_name, column_name\"\"\", \n",
    "            con=self._engine)\n",
    "        \n",
    "        data_cols_not_present = data_cols_needed[~data_cols_needed['name'].isin(\n",
    "            data_cols_present['column_name'])]\n",
    "\n",
    "        and_not_in_json_tbl = data_cols_not_present[~data_cols_not_present['recordname'].isin(\n",
    "            self._json_tables)]\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    def add_varchar_col_to_table(self, schema_name, table_name, column_name, req_width):\n",
    "        sql = f\"\"\"\n",
    "            ALTER TABLE {schema_name}.\"{table_name}\" \n",
    "            ADD COLUMN {column_name.lower()} CHARACTER VARYING ({req_width})\"\"\"\n",
    "        return engine.execute(sql)\n",
    "\n",
    "\n",
    "    def delete_table_entries_for_survey(surveyid, table_name, dry_run=True):\n",
    "        # only drop ones for matching columns because we get different ones from the IR and MR files\n",
    "        if dry_run:\n",
    "            print(f\"Would drop all data rows for survey {surveyid} from {table_name}\")\n",
    "        else:\n",
    "            print(f\"Dropping all data rows for survey {surveyid} from {table_name}\")\n",
    "            meta = sa.MetaData()\n",
    "            tablespec_db = sa.Table(table_name, meta, schema=self._DATA_SCHEMA, \n",
    "                                    autoload=True, autoload_with=engine)\n",
    "            cond = tablespec_db.c.surveyid == surveyid\n",
    "            delete = tablespec_db.delete().where(cond)  \n",
    "            res = engine.execute(delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
