{
 "metadata": {
  "name": "",
  "signature": "sha256:b5bbd6206e8d5f405c190fde308bc31598bf0b78c563a71df7f0fbae1c94d3d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Simple script to go through all the REC* tables in the DHS database and add indexes to all the key columns "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rationale - we loaded all the parsed .DHS tables to a postgres database with a straightforward dump and now want to automate the process of indexing the fields we are likely to want to join on"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import psycopg2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_string = \"host='map-fs1.ndph.ox.ac.uk' port='5433' dbname='dhs_data_pit' \\\n",
      "    user='admin' password='##PASSWORD##'\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = psycopg2.connect(conn_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crs = conn.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Figure out the table names we want to look at, they are those starting with REC or MREC\n",
      "crs.execute(\"select relname from pg_class where relkind='r' and relname ~ 'REC';\")\n",
      "tblNames = [i[0] for i in crs.fetchall()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "crs.execute(\"select relname from pg_class where relkind='i'\")\n",
      "existingIndexes = [i[0] for i in crs.fetchall()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Identifying the columns to index is based on knowledge of the content of the database: they all have \"id\" in the names, in lowercase. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're not doing anything more sophisticated than that for now (such as, for example trying to be intelligent with the \"relationships\" part of the .dcf), partly because it doesn't necessarily cover all possible joins and partly because we haven't really needed to!\n",
      "\n",
      "However there are a few columns we ought to index that get missed by this simple strategy or for joins that are outside the normal hierarchy but would nonetheless be possible - for example REC01.V034 represents \"line number of husband\" so it might be desirable to join based on this field to the husband's record to create some kind of couple's dataset. For now, we haven't addressed this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runIt = 0\n",
      "allUpper = 0\n",
      "replaceExisting = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're just going to make an index on each *ID* column, and covering indice(s) across multiple of them for tables which have more than one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleanSQLTemplate = \"DROP INDEX IF EXISTS dhs_data_tables.{0};\"\n",
      "idxSQLTemplate = \"CREATE INDEX {0} ON {1}({2});\"\n",
      "idxNameTemplate = \"{0}_{1}\"\n",
      "allSQL = []\n",
      "# Create an index for each column with \"id\" in the title, and if there \n",
      "# is more than one (e.g. caseid, bidx) then also create a composite index\n",
      "for tblName in tblNames:\n",
      "    print tblName\n",
      "    crs.execute('SELECT * FROM dhs_data_tables.\"{0}\" LIMIT 1'.format(tblName))\n",
      "    \n",
      "    if allUpper:\n",
      "        tblName = str.upper(tblName)\n",
      "    # note the lowercase will exclude the OGC_FID column which is already indexed\n",
      "    idxfields = [c[0] for c in crs.description if c[0].find(\"id\") != -1]\n",
      "    \n",
      "    # create a separate index on each joining column\n",
      "    #dropidxStmts = [cleanSQLTemplate.format(idxNameTemplate.format(c, str.lower(tblName)))\n",
      "    #                for c in idxfields]\n",
      "    dropidxStmts = []\n",
      "    idxStmts = []\n",
      "    print idxfields\n",
      "    \n",
      "    for c in idxfields:\n",
      "        idxName = idxNameTemplate.format(c, str.lower(tblName))\n",
      "        idxStmt = idxSQLTemplate.format(idxName, 'dhs_data_tables.\"'+ tblName + '\"', c)\n",
      "        if idxName in existingIndexes:\n",
      "            if replaceExisting:\n",
      "                dropidxStmt = cleanSQLTemplate.format(idxName)\n",
      "                dropidxStmts.append(dropidxStmt)\n",
      "                idxStmts.append(idxStmt)\n",
      "                print \"Replacing idx \"+idxName\n",
      "            else:\n",
      "                print \"Skipped existing idx \"+idxName\n",
      "        else:\n",
      "            idxStmts.append(idxStmt)\n",
      "            print \"Adding idx \"+idxName\n",
      "    #idxStmts = [idxSQLTemplate.format(idxNameTemplate.format(c, str.lower(tblName)),\n",
      "    #                                  'dhs_data_tables.\"'+tblName+'\"', c) for c in idxfields]\n",
      "    \n",
      "    # also create a single covering index on all joining columns\n",
      "    if len(idxfields) > 1:\n",
      "        idxName = idxNameTemplate.format(\"allidx\", str.lower(tblName))\n",
      "        allStmt = idxSQLTemplate.format(idxName,\n",
      "                                        'dhs_data_tables.\"'+tblName+'\"', \",\".join(idxfields))\n",
      "        if idxName in existingIndexes:\n",
      "            if replaceExisting:\n",
      "                dropAllStmt = cleanSQLTemplate.format(idxName)\n",
      "                dropidxStmts.append(dropAllStmt)\n",
      "                idxStmts.append(allStmt)\n",
      "                print \"Replacing idx \"+idxName\n",
      "            else:\n",
      "                print \"Skipped existing idx \"+idxName\n",
      "        else:\n",
      "            idxStmts.append(allStmt)\n",
      "            print \"Adding idx \"+idxName\n",
      "    \n",
      "    # also create a covering index on the first two joining columns if there are three \n",
      "    # (or all except the last one, if there's more)\n",
      "    # e.g. surveyid and caseid but not bidx (the cols are in the appropriate order in the CSVs)\n",
      "    if len(idxfields) > 2:\n",
      "        idxName = idxNameTemplate.format(\"twoidx\", str.lower(tblName))\n",
      "        allStmt = idxSQLTemplate.format(idxName,\n",
      "                                        'dhs_data_tables.\"'+tblName+'\"', \",\".join(idxfields[:-1]))\n",
      "        if idxName in existingIndexes:\n",
      "            if replaceExisting:\n",
      "                dropAllStmt = cleanSQLTemplate.format(idxName)\n",
      "                dropidxStmts.append(dropAllStmt)\n",
      "                idxStmts.append(allStmt)\n",
      "                print \"Replacing idx \"+idxName\n",
      "            else:\n",
      "                print \"Skipped existing idx \"+idxName\n",
      "        else:\n",
      "            idxStmts.append(allStmt)\n",
      "            print \"Adding idx \"+idxName\n",
      "    \n",
      "\n",
      "    dropIndexSQL = \"\\n\".join(dropidxStmts)\n",
      "    indexSQL = \"\\n\".join(idxStmts)\n",
      "    if runIt:\n",
      "        if len(dropIndexSQL) > 0:\n",
      "            crs.executescript(dropIndexSQL)\n",
      "        if len(indexSQL) > 0:\n",
      "            crs.executescript(indexSQL)\n",
      "    if len(dropIndexSQL)>0: \n",
      "        allSQL.append(dropIndexSQL)\n",
      "    if len(indexSQL) > 0:\n",
      "        allSQL.append(indexSQL)\n",
      "if runIt:\n",
      "    dbconn.commit()\n",
      "    dbconn.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\".join(allSQL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for l in allSQL:\n",
      "    if len(l) > 0:\n",
      "        print l\n",
      "        crs.execute(l)\n",
      "conn.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}